# 5 事务处理与恢复

## 事务处理

**ACID 原则**：

- 原子性（Atomicity）：事务的本质要求。
  - 事务的本质是多个操作合并为一个步骤，操作包括**读取**和**写入数据记录**
  - 事务中的所有操作要么全部成功执行，要么全部不执行，任何部分的失败都必须回滚到初始状态
- 一致性（Consistency）：数据完整的本质要求
  - 唯一一个可以由开发者控制而不是完全依赖数据库自身保证的属性
  - 在事务开始和结束时，数据库的状态必须是完整且正确的
- 隔离性（Isolation）：并发的本质要求
  - 并发执行的事务相互独立，不会互相影响
  - 并发事务执行时，一个事务的中间状态对其他事务不可见，只有当事务提交后，其他事务才能看到结果
- 持久性（Durability）：数据库系统的本质要求。一旦事务提交成功，数据的修改就会被永久保留，即使系统崩溃或出现故障也不会丢失

**事务管理组件**：

- 事务管理器：协调、调度和跟踪事务的各个步骤
- 锁管理器：保护对资源的访问，防止能可能破坏数据完整性的并发访问
- 页缓存：充当持久性存储（磁盘）和存储引擎其余部分之间的中介
- 日志管理器：记录已应用在缓存页上的操作（日志条目），以便撤销已中止的事务所作出的更改
- 分布式事务协调：在分布式或多分区的环境下，协调跨多个节点的事务执行，确保分布式事务的一致性和完整性。

## 缓冲区管理

### 双层存储体系

1. 页缓存（Page Cache）/ 虚拟磁盘（Virtual Disk）：当内存中没有页副本可用时，读取虚拟磁盘会访问物理存储
2. 操作概述
   - Page In（换入）：将磁盘上的页面加载到内存中的过程
   - Flush（刷写）：将内存中的脏页（被修改过的页面）刷写回磁盘
   - Evict（换出）：将内存中不再需要的页面换出，腾出空间给其他页面

### 缓冲区管理的功能

1. **在内存中保留被缓存的页的内容**：页缓存会将数据库中被频繁访问的页面保留在内存中，减少对磁盘的直接访问，提高访问效率。

2. **把对磁盘页的修改缓冲起来，并且修改的是缓存版本**：修改操作首先应用于内存中的缓存页，而不会立即刷写回磁盘。这样可以避免频繁的磁盘I/O操作。

3. **当被请求的页不在内存中且可用空间足够时，页缓存会换入并返回缓存的版本**：如果请求的页面不在内存中，且内存中有足够的空间，页缓存会将该页面从磁盘加载到内存中，并返回缓存版本供事务使用。

4. **如果请求的页在缓存中，则直接返回缓存的版本**：如果请求的页面已经在缓存中，系统会直接返回缓存页，避免磁盘访问。

5. **如果可用空间不足以放下新页，则换出其他页，被换出的页的内容会刷写回磁盘**：当内存空间不足时，页缓存会选择某些页面换出到磁盘。如果这些页面是**脏页**（被修改过），需要在换出前将其内容刷写回磁盘，确保数据一致性

### 缓存的语义

缓存的修改同步是单向的：缓存提供了对磁盘访问的抽象，将逻辑写操作与物理写操作分离。这使得数据的修改可以首先应用于缓存，而不必立即同步到磁盘。

页缓存的作用：页缓存使我们可以将某些数据结构（例如树的部分结构）保留在内存中，而无需修改算法本身或在内存中物化对象。替换磁盘访问为对页缓存的调用即可实现更高效的数据访问。

请求页的基本步骤：

1. 检查该页是否已被缓存。如果页在缓存中，直接返回缓存的页

2. 如果页不在缓存中，页缓存会将逻辑地址或页 ID 转化为物理地址，加载到内存中，并返回给请求方
3. 一旦返回，存有缓存页内容的缓冲区就被称为**被引用的**
4. 用完页面后，调用方将其归还给页缓存或解除引用
5. 如果希望某些页不被页缓存换出，可以将其**固定**。固定的页会始终保留在内存中，不参与缓存的换出过程
6. 如果某些页被修改，标记为**脏页**，脏页表示内容与磁盘不同步，换出时必须将其刷写到磁盘

### 缓存的回收

保持缓存填满的状态并不总是最优的选择，因为当新页面需要加载时，系统必须换出其他页面，可能导致性能下降。

- 推迟刷写：减少磁盘访问次数，降低中断率
- 提早刷写：让页能被快速换出
- 选择要换出的页：以最优顺序进行刷写
- 保持缓存大小：确保缓存大小在内存范围内
- 避免数据丢失：尽量确保数据在持久存储中得到同步

换出的设计逻辑

1. 检查该页是否与磁盘同步（即已刷写过，或者从未修改过）
2. 检查该页是否被固定或引用。如果可以直接换出，则立即将其换出
3. 脏页需要先刷写到磁盘，然后再换出
   - 每次换出页都刷写磁盘可能导致性能下降，解决方案是：**独立后台进程循环刷写**（例如 PostgreSQL 的后台刷写器）。
4. 如果该页被其他线程使用，则无法换出
   - 如果数据库崩溃，所有未刷写的数据都会丢失。为了解决这一问题，系统使用**检查点进程（Checkpoint Process）和预写日志（WAL）**与页缓存系统配合工作。当数据刷写到磁盘后，WAL 日志可以被丢弃，确保持久性。

### 技术1：在缓存中锁定页

原因：

1. **堆文件的随机性和 B+ 树结构的差异**  
   - 堆文件的随机性导致数据访问没有明显的规律。  
   - B+树结构在业务调用逻辑上存在差异：  
     - B+ 树越靠近顶部越窄，因此**层次较高的节点在大多数读取中会被命中**。  
     - 同时，分裂与合并操作最终也会传播到较高层次的节点。  
2. **频繁的子树结构变化可以一起处理**  
   - 多次删除导致节点合并，随后写入操作又导致分裂。  
   - 不同子树的合并和分裂操作，共同传播到上层结构。  

**锁定页**：  

- 将“大概率会被用到的页”锁定（Pin），减少磁盘访问次数并提高性能。  
- 锁定页的优势：  仅通过**内存中的应用更改**，将操作缓冲到一起，**只做一次磁盘写入**即可，无须多次刷写磁盘，减少磁盘I/O次数。  
- **与页置换策略的关系**：在锁定页的过程中，会涉及到页的置换策略。通过将热点页锁定，可以避免频繁地将重要的页面换出。

### 技术2：页置换策略选择

**FIFO**：对于 B+ 树等数据结构，FIFO 策略可能不适用，因为它无法区分热点页和冷门页。

**LRU（最长时间未使用策略）**：

- 在 FIFO 的基础上，重复访问时将页面放回队列尾部。
- 仍然无法准确识别“频繁访问的页”。
- 大量一次性操作会冲刷缓存，导致缓存污染问题。

**LRU 的优化**：

- 2Q 的 LRU（双队列 LRU，k=2）：将后续访问的页面移入第二个“热队列”，区分“最近访问”和“经常访问”的页面。

- LRU-K：通过跟踪最近K次访问，识别频繁被使用的页，并使用此信息估计下一次访问的时间。

**CLOCK 算法**

- 将页面的引用和访问位保存在环形缓冲中
- 如果访问位为 1 且页面未被引用，修改为 0，检查下一页；如果访问位为 0，则作为换出候选页
- 优点：算法简单，基于CAS比较-置换，无需额外加锁。易于理解和实现。
- 缺点：CLOCK 算法仍然依赖“最近使用时间”，而非“使用频率”作为预测因子

**LFU 和 TinyLFU（最小使用频率策略）**：

- 以使用频率替代“最近使用时间”，追踪页引用事件代替页换入事件
- 核心机制：
- - 频率直方图：维护一个紧凑的缓存访问历史记录。
  - 三层队列结构：
    - 入场队列：新加入元素，使用LRU。
    - 考察队列：维护即将被换出的元素。
    - 保护队列：将需要保留的元素放入队列，优先保护。
- TinyLFU 不是选择要换出哪些元素，而是选择要保留的元素，提高缓存命中率。

**页置换策略的选择与权衡**：减少中断率。简单易实现。降低额外访问的开销。



## 恢复

### Buffer Pool 和 Disk 协同机制

1. 数据库系统需要 Buffer Pool（缓冲池）和 Disk（磁盘）双存储机制进行协同工作，以保证事务的正确性和性能。
   - 对于一个已经提交的事务，即便数据库发生崩溃，事务的更改也不应该丢失
   - 简单方法：在事务提交完成之前，把该事务涉及的所有页面都刷新到磁盘
     - 问题 1：刷写完整的数据页非常浪费，例如，如果只修改了一个字节，却需要刷写整个 16K 页面。 
     - 问题 2：随机 I/O 的刷新效率不高。 

2. 解决方案：使用 Redo 日志  
   - 记录日志：代替直接刷新数据页，将页面的修改操作记录为 Redo 日志。 
   - Redo 日志的优势：  
     - 占用空间小：记录的只是具体修改操作。
     - 顺序写入磁盘：顺序 I/O 比随机 I/O 效率更高

### Redo 日志的设计与格式

#### Redo 日志的设计

- 设计目标：记录事务对数据库物理上的修改，确保数据在崩溃后能够恢复
- 使用顺序写入的方式代替随机 I/O，提高性能

- 静态结构：
  - Redo记录的结构：包含日志类型（Type）、表空间ID（Space ID）、页ID（Page number）和数据内容（Data）
    - MLOG_1BYTE：页面某个偏移量处写入1个字节的数据
      MLOG_2BYTE：页面某个偏移量处写入2个字节的数据
      MLOG_4BYTE：页面某个偏移量处写入4个字节的数据
      MLOG_8BYTE：页面某个偏移量处写入8个字节的数据
      MLOG_WRITE_STRING：页面某个偏移量处写入字节序列的数据
  - Redo日志页的大小：结构和普通数据页类似，通常比正常数据页更大，以便提高写入效率。例如 MySQL 中 Redo 日志的页大小为 512K
  - 日志组织形式：Redo 日志采用顺序组织，有利于快速刷写磁盘
- 动态结构：
  - 事务的原子性保证：通过将多个操作打包成一组不可分割的 Mini-Transaction（MTR）
  - 日志刷写机制：Redo 日志也是双存储结构，拥有独立的 Buffer Pool，以实现快速顺序写入
  - 循环使用：Redo 日志文件采用循环写入方式，容量有限，依赖于 checkpoint 机制来管理刷写状态

#### Redo 日志的格式

- **基础格式**：

  | 字段            | 描述                    |
  | --------------- | ----------------------- |
  | **Type**        | 日志类型，如 MLOG_1BYTE |
  | **Space ID**    | 表空间 ID               |
  | **Page number** | 页 ID                   |
  | **Offset**      | 数据的偏移量            |
  | **Len**         | 数据的长度（可选）      |
  | **Data**        | 日志的具体内容          |

- **常见的日志类型**：

  - 物理层面日志：
    - `MLOG_1BYTE`：在指定位置写入 1 字节。
    - `MLOG_8BYTE`：写入 8 字节。
    - `MLOG_COMP_REC_INSERT`：紧凑行格式记录的插入。
  - 逻辑层面日志：`MLOG_COMP_LIST_START_DELETE` 和 `MLOG_COMP_LIST_END_DELETE`：用于批量删除记录，减少日志条数。

#### 复杂格式与优化

一条 SQL 语句可能修改数据库的多个位置，这些位置包括：数据页面、聚簇索引页面、二级索引页面
此外，还需要更新：File Header、Page Header、Page Directory

面对这种多层次的修改，Redo 日志有两种记录方式：

- 方案 1：在每个修改的地方都记录一条 Redo 日志。这种方法细化到每个位置的具体修改，但可能产生大量的日志，影响性能
- 方案 2：记录从第一个被修改的字节到最后一个被修改的字节之间的所有数据，将其作为一条物理 Redo 日志。这种方式减少了日志的条数，但日志的内容更大，写入数据量较多

是否有另一种记录日志的可能？只记录操作，而不记录物理变化：

1. 物理层面的记录：记录具体位置的物理修改，如某个偏移量的数据更改。
2. 逻辑层面的记录：仅记录操作本身，崩溃恢复时重新执行操作。
3. 混合模式：记录页面插入一条记录的物理要素，但不涉及 Page 系统值的细节。Redo 日志的本质是调用恢复函数的参数组

为了确保数据的唯一性，Redo 日志在记录时需要：

- 对于 聚簇索引：使用主键（PK）列数来唯一标识记录。
- 对于 二级索引：包括索引列数和主键列数。

此外，还需记录字段的存储信息：

- 字段所占存储空间的大小（无论是固定长度还是可变长度）
- 准确记录字段长度

在某些情况下，单独记录每个操作的 Redo 日志效率较低。例如：删除操作：删除索引列值在某个区间范围内的所有记录时，如果每删除一条记录就写一条 Redo 日志，性能会很差

优化方案：使用特殊的 Redo 日志类型，减少日志条数：
    `MLOG_COMP_LIST_START_DELETE`：表示从某条记录开始删除页面中的一系列紧凑行格式的记录。
    `MLOG_COMP_LIST_END_DELETE`：表示删除操作结束，配合 START_DELETE 使用。

针对不同操作的具体日志类型：

- `MLOG_REC_INSERT`：表示插入一条 非紧凑行格式 的记录。
- `MLOG_COMP_REC_INSERT`：表示插入一条 紧凑行格式 的记录。
- `MLOG_COMP_PAGE_CREATE`：表示创建一个存储紧凑行格式记录的页面。
- `MLOG_COMP_REC_DELETE`：表示删除一条紧凑行格式记录。
- `MLOG_COMP_LIST_START_DELETE` 和 `MLOG_COMP_LIST_END_DELETE`：配合使用，用于批量删除紧凑行格式记录。
- `MLOG_ZIP_PAGE_COMPRESS`：表示压缩一个数据页（类型对应十进制数字 51）。

#### Mini-Transaction（MTR）

将一组操作打包成一个整体进行写入

特点：不可分割性。一组操作要么全部成功，要么全部失败，确保操作的原子性

Mini-Transaction 将多页操作整合成一个不可分割的单元。操作写入日志 时，添加特殊类型的 Redo 日志，确保事务组的完整性

- `MLOG_MULTI_REC_END`：结构简单，仅包含一个 `type` 字段（对应十进制数字 31）。系统在恢复时，解析到 `MLOG_MULTI_REC_END` 时，才认为解析到了一组完整的 Redo 日志。如果恢复过程中没有解析到 `MLOG_MULTI_REC_END`，那么之前的 Redo 日志将被直接丢弃，确保完整性

如果一个 Mini-Transaction 中只有一条日志，仍然会被写入日志，并且会添加 `MLOG_MULTI_REC_END` 类型标识

#### Redo 日志的刷盘与缓冲

- Buffer Pool：Redo 日志先写入内存的 Redo Log Buffer Pool，顺序写入，速度最快
- 刷盘时机：
  - Redo Log Buffer 空间不足（达到 50% 阈值）
  - 事务提交时
  - 脏页刷回磁盘时
  - 定时刷盘（如 1 秒刷新一次）
  - 正常关闭服务器
- 硬盘中日志文件：
  - 硬盘中的日志文件分为多个 **512K Block**
  - 日志文件采用**循环写入**，配合 **checkpoint** 机制管理日志状态

### Check Point（检查点）

作用：

- 确定当前系统可以覆盖的日志范围：通过检查点，数据库能够知道哪些操作已经安全地写入数据文件，哪些操作尚未完成
- 减少恢复时间：在发生崩溃时，数据库不必从 Redo 日志的开头开始恢复，而是从最近的 Check Point 开始恢复，极大提高恢复效率

步骤：

1. 计算当前系统可以被覆盖的 Redo 日志对应的 LSN（Log Sequence Number）最大值。

   LSN：日志序列号，是单调递增的全局标识，用于标记日志的位置。

2. 将计算出的信息写入日志文件的管理信息中，记录 Check Point 操作。

Check Point 操作与后台脏页刷写操作是两个并行的操作。当修改页面非常频繁，导致 LSN 快速增长时，数据库需要执行 Check Point 操作，同时触发后台线程刷脏页到磁盘。

- 同步检查点（Sync Checkpoint）：将所有的脏页同步刷写到磁盘，确保磁盘上的数据与内存中的数据完全一致
  缺点：执行时需要暂停所有操作，性能开销较大。

- 模糊检查点（Fuzzy Checkpoint）：部分刷写脏页，不强制一次性刷写所有内容
  在日志中使用特殊标记（如 begin_checkpoint 和 end_checkpoint），记录哪些脏页信息和事务表内容已刷写

### 恢复的过程

1. **确定恢复起点**：选取最近的 checkpoint_lsn
2. **扫描日志**：按顺序恢复操作，确保日志中修改的页面按时间顺序重建
3. **优化**：对同一页面的修改日志批量恢复，减少随机 I/O

### Undo 日志

Undo 日志 是数据库系统中用于保障事务原子性的重要机制。当发生事务回滚或者崩溃恢复时，Undo 日志可以撤销未提交事务的操作，恢复数据到一致状态

基本原理：

- 回滚操作：
  - 对每一条记录进行改动时，数据库都会将修改前的信息记录到 Undo 日志中
  - 如果需要回滚，数据库可以通过 Undo 日志将数据恢复到修改之前的状态
- 针对不同类型的操作：

  - `INSERT`：记录被插入记录的主键，回滚时删除这条记录
  - `DELETE`：记录被删除的完整内容，回滚时重新插入这条记录
  - `UPDATE`：记录被更新的旧值，回滚时恢复旧值

### 预写日志（WAL）

预写日志（Write-Ahead Log，WAL），也称为提交日志（Commit Log），在允许页缓存将页面修改缓存在内存的同时，保证数据库系统的持久性语义

在将受操作影响的缓存页同步到磁盘之前，系统需要先将操作持久化到日志，即：先写日志，再修改页的内容。

当数据库发生崩溃时，系统可以通过重放日志恢复内存中丢失的更改，保证事务的持久性

WAL 采用追加写的方式，已写入的内容是不可变的，而新日志数据被顺序追加到日志尾部

WAL 会保存事务完成的记录，只有当事务的提交记录完成刷盘后，才被视为“已提交”

### Redo 与 Undo 日志的比较

| **对比维度**     | **Redo 日志**                          | **Undo 日志**                          |
| ---------------- | -------------------------------------- | -------------------------------------- |
| **作用**         | 重做操作，保障事务的持久性             | 回滚操作，保障事务的原子性             |
| **记录内容**     | 修改后的数据（物理修改）（后像）       | 修改前的数据（前像）                   |
| **应用时机**     | 数据崩溃恢复时，重做已提交事务的修改   | 事务失败或需要回滚时，撤销未提交的修改 |
| **记录结构**     | 物理层面的修改（例如偏移量和修改内容） | 链表形式串联操作前的状态，支持回滚     |
| **存储位置**     | Redo Log 文件与 Log Buffer             | 回滚段（Rollback Segment）与 Undo Log  |
| **对并发的支持** | 保证数据修改持久化，便于崩溃恢复       | 提供历史数据，支持 MVCC                |

### Steal 和 Force 策略

Steal 策略：允许未提交事务修改过的脏页在事务提交前被写回磁盘。数据库可以偷走事务还未提交的修改内容，提前将这些内容写入磁盘

No-Steal 策略：不允许未提交事务修改过的脏页被写回磁盘

Force 策略：在事务提交之前，将所有事务修改过的页面（脏页）强制刷写到磁盘

No-Force 策略：即使事务提交，事务修改的脏页也可以暂时留在内存中，不强制刷写到磁盘

| **组合策略**            | **恢复需求**          | **特点**                       |
| ----------------------- | --------------------- | ------------------------------ |
| **Steal + Force**       | **Undo / No-Redo**    | 恢复最简单，但提交性能较差。   |
| **Steal + No-Force**    | **Undo + Redo**       | **常用**，性能与恢复需求平衡。 |
| **No-Steal + Force**    | **No-Undo / No-Redo** | 性能最差，恢复最简单。         |
| **No-Steal + No-Force** | **Redo / No-Undo**    | 理论可行，但实际中不可用。     |

### ARIES（Steal / No-Force 的恢复算法）

物理 Redo 日志：提高恢复性能。逻辑 Undo 日志：提高并发性能。

- 使用WAL来实现恢复时重访历史，完整重建数据库状态
- 未提交事务的修改已被撤销，撤销期间构建补偿日志记录

ARIES 恢复的三个阶段：

- 分析阶段：识别页缓存中的脏页，以及崩溃时正在进行的事务，脏页信息用于标识重做阶段的起点。进行事务的清单用于在撤销阶段中回滚未完成的事务
- 重做阶段：重放历史记录直到崩溃点，并将数据库恢复到先前的状态，此阶段会处理未完成的事务，以及哪些已经提交但尚未将修改刷写到持久化存储的事务
- 撤销阶段：回滚所有未完成的事务，并将数据库还原到最后的一致状态。所有操作均按反向时间顺序回滚，为了防止数据库在恢复过程中再次崩溃，撤销事务所做的操作也会被记录到日志中

## 并发控制

### 事务管理器与锁管理器

事务管理器：负责协调、调度和跟踪事务的各个步骤，确保事务可以按照 ACID 原则正确执行。管理事务的生命周期，包括：开始事务、执行事务、提交事务、回滚事务

锁管理器：用于保护对资源的访问，防止并发访问可能破坏数据完整性。通过加锁来协调多个事务对数据的访问，保证事务之间的隔离性

### 并发控制的基本机制

#### 乐观并发控制（OCC）

允许多个事务执行并发的读取和写入，最后确定其执行结果能否被串行化，事务不会被阻塞，而是保留历史操作，并在提交前检查这些历史操作是否存在冲突的可能

#### 多版本并发控制（MVCC）

允许一条记录同时存在多个时间戳的版本，通过这种方式保证事务独到的是数据库过去某个时刻的一致视图。 MVCC 可以是用验证技术来实现（只允许多个更新或事务提交中的某一个获胜，也可以采用无锁机制或者基于二段锁机制

#### 悲观并发控制（PCC）

严格管理和授权对共享资源的访问。基于锁的实现要求事务维护数据库记录上的锁，以防止其他事务修改被加锁的记录或访问当前事务正在修改的记录，直到锁被释放位置，或者不加锁，通过事务调度，维护读取与写入的操作列表以限制事务的执行。悲观的调度可能导致死锁

### 事务隔离级别

并发问题：

- **脏读**（Dirty Read）：**一个事务读取到另外一个事务修改但未提交的数据**

- **不可重复读**（Non-Repeatable Read）：在当执行 SELECT 操作时没有获得读锁或 SELECT 操作执行完后马上释放了读锁；另外一个事务对数据进行了更新，读到了不同的结果

  **读到了其他事务已提交的数据（update）**

- **幻读**（Phantom Read）：同一事务中多次查询结果中出现了新增或删除的记录

  - 当事务 1 两次执行''SELECT ... WHERE''检索一定范围内数据的操作中间，事务 2 在这个表中创建了(如[[INSERT]])了一行新数据，，这条新数据正好满足事务 1 的“WHERE”子句

不可重复读与幻读都是读到其他事务已提交的数据，但是它们针对点不同

- 不可重复读：update
- 幻读：delete，insert

| **隔离级别** | **脏读** | **不可重复读** | **幻读** |
| ------------ | -------- | -------------- | -------- |
| **未提交读** | 可能     | 可能           | 可能     |
| **已提交读** | 不可能   | 可能           | 可能     |
| **可重复读** | 不可能   | 不可能         | 可能     |
| **可串行化** | 不可能   | 不可能         | 不可能   |

#### 未提交读（Read Uncommitted）

最低的隔离级别

如果一个事务已经开始写数据，则另外一个事务则不允许同时进行写操作，但允许其他事务读此行数据

可能发生脏读、不可重复读和幻读

```
事务 1                               	  事务 2  
SELECT dept_id FROM users WHERE id=1  
/* 结果是 1 */  
										UPDATE users SET dept_id=2 WHERE id=1  
										/* 未提交 */  
SELECT dept_id FROM users WHERE id=1  
/* 结果是 2（脏读）*/  
ROLLBACK;  
```

#### 已提交读（Read Committed）

读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行，会对该写锁一直保持直到到事务提交

解决了脏读，但仍可能发生不可重复读和幻读

脏读解决：

```
事务 1                                  事务 2  
SELECT dept_id FROM users WHERE id=1  
/* 结果是 1 */  
										UPDATE users SET dept_id=2 WHERE id=1  
										/* 未提交，持有锁*/  
SELECT dept_id FROM users WHERE id=1  
/* 事务 1 等待 */  
										ROLLBACK;  
SELECT dept_id FROM users WHERE id=1  
/* 结果仍是 1 */  
```

不可重复读问题：

```
事务 1                                  事务 2  
SELECT dept_id FROM users WHERE id=1  
/* 结果是 1 */  
										UPDATE users SET dept_id=2 WHERE id=1  
										COMMIT;  
SELECT dept_id FROM users WHERE id=1  
COMMIT;  
/* 结果是 2（不可重复读）*/  
```

#### 可重复读（Repeatable Read）

介于已提交读和可串行化之间的一种隔离级别

在同一事务中，对同一数据多次读取的结果是一致的，其他事务无法修改当前事务正在读取的数据。

在 InnoDB 中，会在每行数据后添加两个额外的隐藏的值来实现 MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。 在实际操作中，存储的并不是时间，而是事务的版本号，每开启一个新事务，事务的版本号就会递增

MVCC 的操作规则：

- SELECT（快照读）：读取**创建版本号** ≤ 当前事务版本号的数据。忽略**删除版本号** ≤ 当前事务版本号的数据
- INSERT：保存当前事务的版本号为数据行的**创建版本号**
- DELETE：保存当前事务的版本号为数据行的**删除版本号**
- UPDATE：插入一条新记录，保存当前事务的版本号为**创建版本号**；同时，将旧数据的**删除版本号**设置为当前事务的版本号

**快照读**：select

**当前读**：对于会对数据修改的操作（update、insert、delete）都是采用当前读的模式。在执行这几个操作时会读取最新的记录，即使是别的事务提交的数据也可以查询到

假设表 `users` 数据如下：  
| id   | name   | dept_id |
| ---- | ------ | ------- |
| 1    | Jia    | 1       |
| 2    | Zhenyu | 1       |

**事务 1**（当前事务）：  
```
SELECT * FROM users WHERE dept_id=1;
-- 结果：返回两条数据：Jia 和 Zhenyu
UPDATE users SET name=‘Qin’ WHERE dept_id=1
```

这时表格变为：

| id   | name | dept_id |
| ---- | ---- | ------- |
| 1    | Qin  | 1       |
| 2    | Qin  | 1       |

如果此时开始**事务 2**（并发事务）：  

```
UPDATE users SET dept_id=2 WHERE id=1;
★Waiting; --事务2⼀定要等事务1提交之后才会完成
```

**事务 1** 再次读取：  

```
SELECT * FROM users WHERE dept_id=1;
-- 结果：返回两条数据：Qin 和 Qin
COMMIT;
```

在可重复度的隔离级别下：事务 1 在 `update` 后，对该数据加锁，事务 2 无法插入新的数据，这样事务 1 在 `update` 前后数据保持一致，避免了幻读、

原理：Next-Key 锁与 Gap 锁

- **Gap 锁**：锁定索引中的一个区间（间隙），但不包括索引中的记录。防止其他事务在被锁定的索引区间内插入新记录
- **Next-Key 锁**：是行锁（Record Lock）和间隙锁（Gap Lock）的组合，锁定一个索引记录及其前面的间隙

![image-20241217220144938](5事务处理与恢复.assets/image-20241217220144938.png)

只要在一个事务中，第二次 select 多出了 row 就算幻读，所以在这个场景下，是算出现幻读的

理论上，可重复读无法避免幻读

#### 可串行化（Serializable）

高的隔离级别

要求在选定对象上的读锁和写锁保持直到事务结束后才能释放，所以能防住上诉所有问题，但因为是串行化的，所以效率较低

